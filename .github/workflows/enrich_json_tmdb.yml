# .github/workflows/enrich_json_tmdb.yml
name: Enriquecer JSON con TMDB (es-MX) desde URL

permissions:
  contents: write

on:
  workflow_dispatch:
    inputs:
      json_url:
        description: "URL del JSON a enriquecer (raw). Ej: peliculas.json o peliculas_part001.json"
        required: true
      output_dir:
        description: "Carpeta de salida en la raiz"
        required: false
        default: "tmdb_enriched"
      chunk_size:
        description: "Max. cantidad de samples por archivo (para split)"
        required: false
        default: "2000"
      language:
        description: "Idioma preferido TMDB (LatAm recomendado: es-MX)"
        required: false
        default: "es-MX"
      fallback_language:
        description: "Idioma fallback para overview (ej: en-US)"
        required: false
        default: "en-US"
      only_fill_empty:
        description: "Solo rellenar campos vacios (true/false)"
        required: false
        default: "true"
      min_delay_ms:
        description: "Delay minimo entre requests TMDB (ms) para evitar rate-limit"
        required: false
        default: "150"

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install dependencies
        run: |
          pip install --no-cache-dir requests

      - name: Enrich JSON with TMDB
        env:
          TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
          JSON_URL: ${{ github.event.inputs.json_url }}
          OUTPUT_DIR: ${{ github.event.inputs.output_dir }}
          CHUNK_SIZE: ${{ github.event.inputs.chunk_size }}
          LANGUAGE: ${{ github.event.inputs.language }}
          FALLBACK_LANGUAGE: ${{ github.event.inputs.fallback_language }}
          ONLY_FILL_EMPTY: ${{ github.event.inputs.only_fill_empty }}
          MIN_DELAY_MS: ${{ github.event.inputs.min_delay_ms }}
        run: |
          python <<'PY'
          import os
          import re
          import json
          import time
          import requests
          from urllib.parse import urlparse
          from collections import OrderedDict

          API_KEY = os.environ.get("TMDB_API_KEY", "").strip()
          JSON_URL = os.environ.get("JSON_URL", "").strip()
          OUTPUT_DIR = os.environ.get("OUTPUT_DIR", "tmdb_enriched").strip()
          CHUNK_SIZE = int((os.environ.get("CHUNK_SIZE") or "2000").strip())
          LANGUAGE = (os.environ.get("LANGUAGE") or "es-MX").strip()
          FALLBACK_LANGUAGE = (os.environ.get("FALLBACK_LANGUAGE") or "en-US").strip()
          ONLY_FILL_EMPTY = (os.environ.get("ONLY_FILL_EMPTY", "true").strip().lower() == "true")
          MIN_DELAY_MS = int((os.environ.get("MIN_DELAY_MS") or "150").strip())

          if not API_KEY:
              raise SystemExit("Falta secrets.TMDB_API_KEY")
          if not JSON_URL:
              raise SystemExit("Falta json_url")

          os.makedirs(OUTPUT_DIR, exist_ok=True)

          TMDB_BASE = "https://api.themoviedb.org/3"
          IMG_BASE = "https://image.tmdb.org/t/p/original"

          # -----------------------
          # Rate-limit soft throttle
          # -----------------------
          _last_call = 0.0
          def _throttle():
              global _last_call
              now = time.time()
              wait = (MIN_DELAY_MS / 1000.0) - (now - _last_call)
              if wait > 0:
                  time.sleep(wait)
              _last_call = time.time()

          def tmdb_get(path, params=None, retries=4):
              url = TMDB_BASE + path
              params = dict(params or {})
              params["api_key"] = API_KEY

              for attempt in range(retries):
                  _throttle()
                  try:
                      r = requests.get(url, params=params, timeout=30)
                  except requests.RequestException:
                      if attempt == retries - 1:
                          raise
                      time.sleep(1.0 + attempt)
                      continue

                  if r.status_code == 429:
                      retry_after = int(r.headers.get("Retry-After", "2") or "2")
                      time.sleep(retry_after + (attempt * 1.5))
                      continue

                  if 500 <= r.status_code < 600:
                      time.sleep(1.0 + attempt)
                      continue

                  r.raise_for_status()
                  return r.json()

              r.raise_for_status()
              return r.json()

          # -----------------------
          # Descarga JSON por URL
          # -----------------------
          raw = requests.get(JSON_URL, timeout=60)
          raw.raise_for_status()
          data = raw.json()

          def safe_basename_from_url(u: str) -> str:
              try:
                  p = urlparse(u)
                  name = os.path.basename(p.path) or "input.json"
              except Exception:
                  name = "input.json"
              if not name.lower().endswith(".json"):
                  name += ".json"
              return name

          in_name = safe_basename_from_url(JSON_URL)
          stem = re.sub(r"\.json$", "", in_name, flags=re.IGNORECASE)

          # -----------------------
          # Normalizacion del titulo
          # -----------------------
          YEAR_RE = re.compile(r"\b(19\d{2}|20\d{2})\b")
          JUNK_RE = re.compile(
              r"(\b(1080p|720p|2160p|4k|hdr|sdr|webrip|web-dl|bluray|brrip|dvdrip|x264|x265|h\.?264|h\.?265|hevc|aac|ac3|dts|latino|castellano|subtitulado|sub|dual|multi|esp|eng|vose)\b)",
              re.IGNORECASE,
          )
          BRACKETS_RE = re.compile(r"[\[\(\{].*?[\]\)\}]")
          SEP_RE = re.compile(r"[._\-]+")
          MULTISPACE_RE = re.compile(r"\s{2,}")

          def extract_year(text: str) -> str:
              if not text:
                  return ""
              yrs = YEAR_RE.findall(text)
              return yrs[-1] if yrs else ""

          def clean_title(name: str) -> str:
              t = (name or "").strip()
              if not t:
                  return ""
              t = BRACKETS_RE.sub(" ", t)
              t = SEP_RE.sub(" ", t)
              t = JUNK_RE.sub(" ", t)
              t = re.sub(r"\s+\b(19\d{2}|20\d{2})\b\s*$", "", t).strip()
              t = MULTISPACE_RE.sub(" ", t).strip()
              return t

          def norm_cmp(s: str) -> str:
              s = (s or "").strip().lower()
              s = re.sub(r"\s+", " ", s)
              return s

          # Heuristica simple: detectar si el titulo "ya parece español"
          ES_CHARS_RE = re.compile(r"[áéíóúñü¿¡]", re.IGNORECASE)
          ES_WORDS_RE = re.compile(r"\b(el|la|los|las|un|una|unos|unas|de|del|y|en|para|con|sin|por|mi|tu|su)\b", re.IGNORECASE)

          def looks_spanish(s: str) -> bool:
              t = (s or "").strip()
              if not t:
                  return False
              if ES_CHARS_RE.search(t):
                  return True
              if ES_WORDS_RE.search(t):
                  return True
              return False

          # Regla pedida:
          # - Si el nombre actual parece EN (o al menos NO español),
          #   y TMDB trae title en es-MX distinto -> reemplazamos.
          # - Si TMDB no trae title es-MX (vacio) o es igual -> mantenemos.
          def should_replace_title_with_es(orig_title: str, tmdb_title_es: str) -> bool:
              if not orig_title or not tmdb_title_es:
                  return False
              if looks_spanish(orig_title):
                  return False  # ya esta en español (o muy probable)
              if norm_cmp(orig_title) == norm_cmp(tmdb_title_es):
                  return False  # es el mismo titulo
              # Si el tmdb es-MX "parece español" o al menos difiere, lo aceptamos
              if looks_spanish(tmdb_title_es):
                  return True
              # Aun si no parece español (a veces TMDB no traduce), no reemplazamos
              return False

          # -----------------------
          # TMDB Search + Details + Images
          # -----------------------
          def search_movie(query: str, year: str, lang: str):
              params = {"language": lang, "query": query, "include_adult": "false"}
              if year:
                  params["year"] = year
              res = tmdb_get("/search/movie", params=params)
              return res.get("results", []) or []

          def fetch_details(movie_id: int, lang: str):
              det = tmdb_get(f"/movie/{movie_id}", params={"language": lang})
              imgs = tmdb_get(
                  f"/movie/{movie_id}/images",
                  params={"include_image_language": "es,en,null"}
              )
              return det, imgs

          def pick_logo_url(imgs: dict) -> str:
              logos = (imgs or {}).get("logos") or []
              def score(x):
                  iso = x.get("iso_639_1")
                  if iso == "es":
                      return 0
                  if iso == "en":
                      return 1
                  if iso in (None, "", "null"):
                      return 2
                  return 3
              logos_sorted = sorted(logos, key=score)
              if not logos_sorted:
                  return ""
              fp = logos_sorted[0].get("file_path") or ""
              return (IMG_BASE + fp) if fp else ""

          def to_img_url(path: str) -> str:
              return (IMG_BASE + path) if path else ""

          cache = {}  # key: (clean, year) -> hit dict or None

          def should_set(current_val: str) -> bool:
              if not ONLY_FILL_EMPTY:
                  return True
              return not (current_val or "").strip()

          def enrich_sample(sample: dict) -> dict:
              # Solo peliculas
              tipo = (sample.get("type") or "").upper().strip()
              if tipo and tipo != "PELICULA":
                  return sample

              orig_name = (sample.get("name") or "").strip()
              orig_year = (sample.get("anio") or "").strip()
              if not orig_name:
                  return sample

              q_clean = clean_title(orig_name)
              year_for_search = orig_year or extract_year(orig_name)

              cache_key = (q_clean.lower(), year_for_search)
              hit = cache.get(cache_key, None)

              if cache_key not in cache:
                  hit = None

                  # Busquedas (idioma preferido, luego en-US)
                  results = search_movie(q_clean, year_for_search, LANGUAGE)
                  if not results and year_for_search:
                      results = search_movie(q_clean, "", LANGUAGE)
                  if not results:
                      results = search_movie(q_clean, year_for_search, "en-US")
                  if not results and year_for_search:
                      results = search_movie(q_clean, "", "en-US")

                  if results:
                      movie = results[0]
                      mid = movie.get("id")
                      if mid:
                          det_es, imgs = fetch_details(mid, LANGUAGE)

                          det_fb = None
                          if FALLBACK_LANGUAGE and FALLBACK_LANGUAGE != LANGUAGE:
                              try:
                                  det_fb, _ = fetch_details(mid, FALLBACK_LANGUAGE)
                              except Exception:
                                  det_fb = None

                          title_es = (det_es.get("title") or "").strip()
                          overview_es = (det_es.get("overview") or "").strip()

                          title_fb = (det_fb.get("title") or "").strip() if det_fb else ""
                          overview_fb = (det_fb.get("overview") or "").strip() if det_fb else ""

                          release_date = (det_es.get("release_date") or "").strip()
                          tmdb_year = release_date[:4] if release_date else ""
                          runtime = det_es.get("runtime") or 0
                          genres = [g.get("name","").strip() for g in (det_es.get("genres") or []) if g.get("name")]

                          poster = to_img_url(det_es.get("poster_path") or "")
                          backdrop = to_img_url(det_es.get("backdrop_path") or "")
                          logo = pick_logo_url(imgs)

                          hit = {
                              # Importante: guardamos separado el titulo ES y el fallback
                              "title_es": title_es,
                              "title_fb": title_fb,
                              "overview_es": overview_es,
                              "overview_fb": overview_fb,

                              "year": tmdb_year,
                              "genres": ", ".join([g for g in genres if g]),
                              "runtime": (f"{int(runtime)} min" if runtime else ""),
                              "poster": poster,
                              "backdrop": backdrop,
                              "logo": logo,
                          }

                  cache[cache_key] = hit

              if not hit:
                  return sample

              # --- TITULO (regla pedida) ---
              # Caso 1: name vacio -> poner ES si existe, sino fallback
              if should_set(sample.get("name","")):
                  if hit.get("title_es"):
                      sample["name"] = hit["title_es"]
                  elif hit.get("title_fb"):
                      sample["name"] = hit["title_fb"]
              else:
                  # Caso 2: name NO vacio -> si parece ingles y existe title_es distinto -> reemplazar
                  if should_replace_title_with_es(orig_name, hit.get("title_es","")):
                      sample["name"] = hit["title_es"]
                  # caso contrario: se mantiene tal cual

              # --- DESCRIPCION ---
              # Aca mantenemos la idea original: llenar vacio con es-MX, si es-MX vacio usar fallback
              if should_set(sample.get("descripcion","")):
                  if hit.get("overview_es"):
                      sample["descripcion"] = hit["overview_es"]
                  elif hit.get("overview_fb"):
                      sample["descripcion"] = hit["overview_fb"]

              # --- RESTO (solo si falta, o overwrite si ONLY_FILL_EMPTY=false) ---
              if should_set(sample.get("anio","")) and hit.get("year"):
                  sample["anio"] = hit["year"]

              if should_set(sample.get("genero","")) and hit.get("genres"):
                  sample["genero"] = hit["genres"]

              if should_set(sample.get("duracion","")) and hit.get("runtime"):
                  sample["duracion"] = hit["runtime"]

              if should_set(sample.get("icono","")) and hit.get("poster"):
                  sample["icono"] = hit["poster"]

              if should_set(sample.get("iconoHorizontal","")) and hit.get("backdrop"):
                  sample["iconoHorizontal"] = hit["backdrop"]

              if should_set(sample.get("iconpng","")) and hit.get("logo"):
                  sample["iconpng"] = hit["logo"]

              # asegurar campos existan
              sample.setdefault("icono", sample.get("icono","") or "")
              sample.setdefault("iconoHorizontal", sample.get("iconoHorizontal","") or "")
              sample.setdefault("iconpng", sample.get("iconpng","") or "")
              sample.setdefault("type", sample.get("type","") or "PELICULA")
              sample.setdefault("descripcion", sample.get("descripcion","") or "")
              sample.setdefault("anio", sample.get("anio","") or "")
              sample.setdefault("genero", sample.get("genero","") or "")
              sample.setdefault("duracion", sample.get("duracion","") or "")

              return sample

          # -----------------------
          # Recorrer estructura
          # -----------------------
          total_samples = 0
          enriched_samples = 0
          skipped_samples = 0

          for record in data:
              samples = record.get("samples") or []
              new_samples = []
              for s in samples:
                  total_samples += 1
                  t = (s.get("type") or "").upper().strip()
                  if t and t != "PELICULA":
                      skipped_samples += 1
                      new_samples.append(s)
                      continue
                  before = json.dumps(s, sort_keys=True, ensure_ascii=False)
                  s2 = enrich_sample(s)
                  after = json.dumps(s2, sort_keys=True, ensure_ascii=False)
                  if before != after:
                      enriched_samples += 1
                  new_samples.append(s2)
              record["samples"] = new_samples

              # Si record.name vacio, intentar poner primer genero
              if (not (record.get("name") or "").strip()):
                  g = ""
                  for s in new_samples:
                      g = (s.get("genero") or "").split(",")[0].strip()
                      if g:
                          break
                  if g:
                      record["name"] = g

          # -----------------------
          # Split por cantidad total de samples
          # -----------------------
          def split_records_by_samples(records, max_samples):
              parts = []
              cur = []
              cur_count = 0
              for r in records:
                  s = r.get("samples", []) or []
                  if cur and (cur_count + len(s) > max_samples):
                      parts.append(cur)
                      cur = []
                      cur_count = 0
                  cur.append(r)
                  cur_count += len(s)
              if cur:
                  parts.append(cur)
              return parts

          parts = split_records_by_samples(data, CHUNK_SIZE)

          # -----------------------
          # Guardar salida
          # -----------------------
          if len(parts) == 1:
              out_path = os.path.join(OUTPUT_DIR, f"{stem}.enriched.json")
              with open(out_path, "w", encoding="utf-8") as f:
                  json.dump(parts[0], f, indent=2, ensure_ascii=False)
          else:
              files = []
              for i, part in enumerate(parts, start=1):
                  fn = f"{stem}.enriched_part{i:03d}.json"
                  files.append(fn)
                  out_path = os.path.join(OUTPUT_DIR, fn)
                  with open(out_path, "w", encoding="utf-8") as f:
                      json.dump(part, f, indent=2, ensure_ascii=False)

              manifest = {
                  "source_url": JSON_URL,
                  "total_parts": len(parts),
                  "chunk_size_samples": CHUNK_SIZE,
                  "files": files,
                  "language": LANGUAGE,
                  "fallback_language": FALLBACK_LANGUAGE,
                  "only_fill_empty": ONLY_FILL_EMPTY
              }
              with open(os.path.join(OUTPUT_DIR, f"{stem}.enriched_manifest.json"), "w", encoding="utf-8") as f:
                  json.dump(manifest, f, indent=2, ensure_ascii=False)

          report = {
              "source_url": JSON_URL,
              "records": len(data),
              "total_samples": total_samples,
              "enriched_samples_changed": enriched_samples,
              "skipped_non_movie_samples": skipped_samples,
              "language": LANGUAGE,
              "fallback_language": FALLBACK_LANGUAGE,
              "only_fill_empty": ONLY_FILL_EMPTY,
              "title_rule": "Si el titulo actual NO parece español y TMDB trae title_es distinto (es-MX), se reemplaza; si no, se mantiene."
          }
          with open(os.path.join(OUTPUT_DIR, f"{stem}.report.json"), "w", encoding="utf-8") as f:
              json.dump(report, f, indent=2, ensure_ascii=False)

          print(json.dumps(report, indent=2, ensure_ascii=False))
          PY

      - name: Commit and Push
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "${{ github.event.inputs.output_dir }}"
          if ! git diff --cached --exit-code; then
            git commit -m "Enriquecer JSON con TMDB (es-MX)"
            git push
          else
            echo "No hay cambios"
          fi
